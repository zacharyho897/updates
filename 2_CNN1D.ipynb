{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "## CNN1D\n",
    "\n",
    "### Inputs (7)\n",
    "\n",
    "|Feature|Description|\n",
    "|:--:|:--:|\n",
    "|j1_ptrel|ratio of the pT of each consistent to the pT of the jet|\n",
    "|j1_etarot|rotated eta of each constituent|\n",
    "|j1_phirot|rotated phi of each constituent|\n",
    "|j1_erel|ratio of the energy of each consistent to the pT of the jet|\n",
    "|j1_deltaR|sqrt ((Δeta)2 + (Δ phi)2 )|\n",
    "|j1_costhetarel|cos (angle (constituent, jet))|\n",
    "|j1_pdgid|PDG ID number of the constituent|\n",
    "|(j1_index)|This will be dropped in training|\n",
    "\n",
    "MaxParticles: 100\n",
    "\n",
    "### Labels (5)\n",
    "\n",
    "|Label|Description|\n",
    "|:--:|:--:|\n",
    "|j_g|Gluon jet|\n",
    "|j_q|Light-quark jet|\n",
    "|j_w|W-boson|\n",
    "|j_z|Z-boson|\n",
    "|j_t|Top-quark|\n",
    "|(j1_index)|This will be dropped in training|\n",
    "\n",
    "### Model structure\n",
    "\n",
    "    Model: \"model\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                Output Shape                Param #   \n",
    "    =================================================================\n",
    "    input (InputLayer)          [(None, 100, 7)]            0         \n",
    "    _________________________________________________________________\n",
    "    conv1_relu_1 (Conv1D)       (None, 100, 8)              232       \n",
    "    _________________________________________________________________\n",
    "    conv1_relu_2 (Conv1D)       (None, 50, 4)               132       \n",
    "    _________________________________________________________________\n",
    "    conv1_relu_3 (Conv1D)       (None, 17, 2)               34        \n",
    "    _________________________________________________________________\n",
    "    flatten (Flatten)           (None, 34)                  0         \n",
    "    _________________________________________________________________\n",
    "    fc1_relu (Dense)            (None, 32)                  1120      \n",
    "    _________________________________________________________________\n",
    "    rnn_densef (Dense)          (None, 5)                   165       \n",
    "    =================================================================\n",
    "    Total params: 1,683\n",
    "    Trainable params: 1,683\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________\n",
    "\n",
    "\n",
    "#### Input Shape: (100, 7) *100 particles, 7 features*\n",
    "\n",
    "#### Conv1D Layers (3)\n",
    "\n",
    "    Filters:                8 + 4 + 2\n",
    "    Kernel_size:            4 + 4 + 4\n",
    "    Strides:                1 + 2 + 3\n",
    "    Regularizer:            Lasso regularization (l = 1e-4)\n",
    "    Activation function:    Relu\n",
    "    Kernel initializer:     he_normal\n",
    "\n",
    "#### Dense Layers (1)\n",
    "\n",
    "    Perceptrons:            32\n",
    "    Activation function:    lecun_uniform\n",
    "    Regularizer:            Lasso regularization (l = 1e-4)\n",
    "    Kernel initializer:     lecun_uniform\n",
    "\n",
    "#### Output layer (1)\n",
    "\n",
    "    Output:                 5-class Classification\n",
    "    Activation function:    Softmax\n",
    "    Kernel initializer:     lecun_uniform\n",
    "\n",
    "##### Learning rate:         1e-4\n",
    "\n",
    "##### Optimizer:             Adam\n",
    "\n",
    "##### Loss function:         categorical_crossentropy\n",
    "\n",
    "##### Metrics:               Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network is an image-based deep neural network. [Useful Reading](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
    "\n",
    "It is a very good entry to know about how image classification deep learning application could use in our jet classification project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From CNN, we will tend to use low-level features as our input for training because they would produce better results than high-level features. First of all, just like in DNN, we need to take all the features and labels we need from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use one data file:\n",
    "h5File = h5py.File('data/processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth_0.z', 'r')\n",
    "treeArray = h5File['t_allpar_new'][()]\n",
    "\n",
    "h5File.close()\n",
    "\n",
    "print(treeArray.shape)\n",
    "\n",
    "# List of features to use\n",
    "features = ['j1_ptrel', 'j1_etarot', 'j1_phirot', 'j1_erel', 'j1_deltaR', 'j1_costhetarel', 'j1_pdgid', 'j_index']\n",
    "\n",
    "# List of labels to use\n",
    "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t', 'j_index']\n",
    "\n",
    "# Convert to dataframe\n",
    "features_labels_df = pd.DataFrame(treeArray,columns=list(set(features+labels)))\n",
    "features_labels_df = features_labels_df.drop_duplicates()\n",
    "\n",
    "features_df = features_labels_df[features]\n",
    "labels_df = features_labels_df[labels]\n",
    "labels_df = labels_df.drop_duplicates()\n",
    "\n",
    "# Convert to numpy array \n",
    "features_val = features_df.values\n",
    "labels_val = labels_df.values     \n",
    "\n",
    "if 'j_index' in features:\n",
    "    features_val = features_val[:,:-1] # drop the j_index feature\n",
    "if 'j_index' in labels:\n",
    "    labels_val = labels_val[:,:-1] # drop the j_index label\n",
    "    print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to preprocess the data from constituents(particles) to jets in the way of 1d array. We implemented tqdm to know the preprocessing progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxParticles = 100\n",
    "features_2dval = np.zeros((len(labels_df), MaxParticles, len(features)-1))\n",
    "for i in tqdm(range(0, len(labels_df))):\n",
    "    features_df_i = features_df[features_df['j_index']==labels_df['j_index'].iloc[i]]\n",
    "    index_values = features_df_i.index.values\n",
    "    features_val_i = features_val[np.array(index_values), :]\n",
    "    nParticles = len(features_val_i)\n",
    "    features_val_i = features_val_i[features_val_i[:, 0].argsort()[::-1]] # sort descending by ptrel\n",
    "    if nParticles > MaxParticles:\n",
    "        features_val_i =  features_val_i[0:MaxParticles, :]\n",
    "    else:        \n",
    "        features_val_i = np.concatenate([features_val_i, np.zeros((MaxParticles-nParticles, len(features)-1))])\n",
    "    features_2dval[i, :, :] = features_val_i\n",
    "features_val = features_2dval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will do our favorite train_test_split using scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_val, labels_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to normalize our X(predictor) input for the CNN model to recognize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize conv inputs\n",
    "reshape_X_train_val = X_train.reshape(X_train.shape[0]*X_train.shape[1], X_train.shape[2])\n",
    "scaler = preprocessing.StandardScaler().fit(reshape_X_train_val)\n",
    "for p in range(X_train.shape[1]):\n",
    "    X_train[:,p,:] = scaler.transform(X_train[:, p, :])\n",
    "    X_test[:,p,:] = scaler.transform(X_test[:, p, :])    \n",
    "\n",
    "if 'j_index' in labels:\n",
    "    labels = labels[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the model from the description at the top of the page. To understand why the model is construct this way, [Useful Reading](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) is really helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l1Reg = 0.0001\n",
    "Inputs = Input(shape = (100,7))\n",
    "x = Conv1D(filters=8, kernel_size=4, strides=1, padding='same',\n",
    "               kernel_initializer='he_normal', use_bias=True, name='conv1_relu_1',\n",
    "               activation = 'relu', kernel_regularizer=l1(l1Reg))(Inputs)\n",
    "x = Conv1D(filters=4, kernel_size=4, strides=2, padding='same',\n",
    "               kernel_initializer='he_normal', use_bias=True, name='conv1_relu_2',\n",
    "               activation = 'relu', kernel_regularizer=l1(l1Reg))(x)\n",
    "x = Conv1D(filters=2, kernel_size=4, strides=3, padding='same',\n",
    "               kernel_initializer='he_normal', use_bias=True, name='conv1_relu_3',\n",
    "               activation = 'relu', kernel_regularizer=l1(l1Reg))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu', kernel_initializer='lecun_uniform', \n",
    "              name='fc1_relu', kernel_regularizer=l1(l1Reg))(x)\n",
    "predictions = Dense(5, activation='softmax', kernel_initializer='lecun_uniform', name='rnn_densef')(x)\n",
    "model = Model(inputs=Inputs, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have five output labels, we will use `categorial_crossentropy` in our loss hyper parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0001)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size = 1024, epochs = 100, \n",
    "                    validation_split = 0.25, shuffle = True, callbacks = None,\n",
    "                    use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in DNN, we will use the same methods to evaluate our training performance for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurveLoss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], linewidth=1)\n",
    "    plt.plot(history.history['val_loss'], linewidth=1)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningCurveLoss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRoc(features_val, labels_val, labels, model, outputSuffix=''):\n",
    "    labels_pred = model.predict(features_val)\n",
    "    df = pd.DataFrame()\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    auc1 = {}\n",
    "    plt.figure()       \n",
    "    for i, label in enumerate(labels):\n",
    "        df[label] = labels_val[:,i]\n",
    "        df[label + '_pred'] = labels_pred[:,i]\n",
    "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
    "        auc1[label] = auc(fpr[label], tpr[label])\n",
    "        plt.plot(fpr[label],tpr[label],label='%s tagger, AUC = %.1f%%'%(label.replace('j_',''),auc1[label]*100.))\n",
    "    plt.xlabel(\"Background Efficiency\")\n",
    "    plt.ylabel(\"Signal Efficiency\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim(0.001,1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('%s ROC Curve'%(outputSuffix))\n",
    "    #plt.savefig('%s_ROC_Curve.png'%(outputSuffix))\n",
    "    return labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = makeRoc(X_test, y_test, labels, model, outputSuffix='Conv1d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Congratulations on finishing CNN1D tutorial. Now think how CNN2D will work and finish reading this [article](https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
