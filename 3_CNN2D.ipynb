{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "## CNN2D\n",
    "\n",
    "### Inputs (3)\n",
    "\n",
    "|Feature|Description|\n",
    "|:--:|:--:|\n",
    "|j1_etarot|rotated eta of each constituent|\n",
    "|j1_phirot|rotated phi of each constituent|\n",
    "|j1_ptrel|ratio of the pT of each consistent to the pT of the jet|\n",
    "|(j1_index)|This will be dropped in training|\n",
    "\n",
    "MaxParticles: 100\n",
    "\n",
    "### Labels (5)\n",
    "\n",
    "Label|Description\n",
    ":--:|:--:\n",
    "j_g|Gluon jet\n",
    "j_q|Light-quark jet\n",
    "j_w|W-boson\n",
    "j_z|Z-boson\n",
    "j_t|Top-quark\n",
    "(j1_index)|This will be dropped in training\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "    2D feature map (etarot, phirot) weighted by ptrel\n",
    "    binning: 40Ã—40, range: [0.8,0.8] in (etarot, phirot)\n",
    "    Pixelated each jet as input to 2D CNN.\n",
    "    Jet image can also be used as input to the ResNet-50\n",
    "\n",
    "### Model structure\n",
    "\n",
    "    Model: \"model\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    input_1 (InputLayer)         [(None, 40, 40, 1)]       0         \n",
    "    _________________________________________________________________\n",
    "    conv1_relu (Conv2D)          (None, 40, 40, 8)         976       \n",
    "    _________________________________________________________________\n",
    "    conv2_relu (Conv2D)          (None, 20, 20, 4)         292       \n",
    "    _________________________________________________________________\n",
    "    conv3_relu (Conv2D)          (None, 10, 10, 2)         74        \n",
    "    _________________________________________________________________\n",
    "    flatten (Flatten)            (None, 200)               0         \n",
    "    _________________________________________________________________\n",
    "    dense (Dense)                (None, 32)                6432      \n",
    "    _________________________________________________________________\n",
    "    output_softmax (Dense)       (None, 5)                 165       \n",
    "    =================================================================\n",
    "    Total params: 7,939\n",
    "    Trainable params: 7,939\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________\n",
    "\n",
    "#### Input Shape: (40, 40, 1)\n",
    "\n",
    "#### Conv2d Layers (3)\n",
    "\n",
    "    Kernel Size:            (11,11) + (3,3) + (3,3)\n",
    "    Strides:                (1,1) + (2,2) + (2,2)\n",
    "    Number of Filters:      8 + 4 + 2\n",
    "    Activation function:    Relu\n",
    "    Kernel initializer:     he_normal\n",
    "    Padding:                Same\n",
    "\n",
    "#### Flatten Layers (1)\n",
    "\n",
    "#### Dense Layers (1)\n",
    "\n",
    "    Perceptrons:            32\n",
    "    Activation function:    Relu\n",
    "\n",
    "#### Output layer (1)\n",
    "\n",
    "    Output:                 5-class Classification\n",
    "    Activation function:    Softmax\n",
    "    Kernel initializer:     lecun_uniform\n",
    "\n",
    "##### Learning rate: 1e-4\n",
    "\n",
    "##### Optimizer: Adam\n",
    "\n",
    "##### Loss function: categorical_crossentropy\n",
    "\n",
    "##### Metrics: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to CNN2D tutorial. For CNN2D, it is pretty obvious that the input for this model is 2D images. Images are actually 2D array with values in each pixels. That is how we will preprocess our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still the same old get features and labels data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use one data file:\n",
    "h5File = h5py.File('data/processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth_0.z', 'r')\n",
    "treeArray = h5File['t_allpar_new'][()]\n",
    "\n",
    "h5File.close()\n",
    "\n",
    "print(treeArray.shape)\n",
    "\n",
    "# List of features to use\n",
    "features = ['j1_etarot', 'j1_phirot', 'j1_ptrel', 'j_index']\n",
    "\n",
    "# List of labels to use\n",
    "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t', 'j_index']\n",
    "\n",
    "# Convert to dataframe\n",
    "features_labels_df = pd.DataFrame(treeArray,columns=list(set(features+labels)))\n",
    "features_labels_df = features_labels_df.drop_duplicates()\n",
    "\n",
    "features_df = features_labels_df[features]\n",
    "labels_df = features_labels_df[labels]\n",
    "labels_df = labels_df.drop_duplicates()\n",
    "\n",
    "# Convert to numpy array \n",
    "features_val = features_df.values\n",
    "labels_val = labels_df.values     \n",
    "\n",
    "if 'j_index' in features:\n",
    "    features_val = features_val[:,:-1] # drop the j_index feature\n",
    "if 'j_index' in labels:\n",
    "    labels_val = labels_val[:,:-1] # drop the j_index label\n",
    "    print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will process our data into an 40x40 2d array for each jet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BinsX = 40\n",
    "MinX = -0.8\n",
    "MaxX = 0.8\n",
    "BinsY = 40\n",
    "MinY = -1.0\n",
    "MaxY = 1.0\n",
    "features_2dval = np.zeros((len(labels_df), BinsX, BinsY, 1))\n",
    "for i in tqdm(range(0, len(labels_df))):\n",
    "    features_df_i = features_df[features_df['j_index']==labels_df['j_index'].iloc[i]]\n",
    "    index_values = features_df_i.index.values\n",
    "\n",
    "    xbins = np.linspace(MinX,MaxX,BinsX+1)\n",
    "    ybins = np.linspace(MinY,MaxY,BinsY+1)\n",
    "\n",
    "    x = features_df_i[features[1]]           \n",
    "    y = features_df_i[features[0]]\n",
    "    w = features_df_i[features[2]]\n",
    "\n",
    "    hist, xedges, yedges = np.histogram2d(x, y, weights=w, bins=(xbins,ybins))\n",
    "\n",
    "    for ix in range(0,BinsX):\n",
    "        for iy in range(0,BinsY):\n",
    "            features_2dval[i,ix,iy,0] = hist[ix,iy]\n",
    "features_val = features_2dval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same old train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_val, labels_val, test_size=0.2, random_state=42)\n",
    " \n",
    "if 'j_index' in labels:\n",
    "    labels = labels[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Notice that the kernel size and strides hyperparameters were changed to 2d vectors instead of 1d values, and the input shape is also changed to our image resolution and one image per input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Inputs = Input(shape=(40, 40, 1,))\n",
    "x = Conv2D(filters=8, kernel_size=(11,11), strides=(1,1), padding='same',\n",
    "           kernel_initializer='he_normal', use_bias=True, name='conv1_relu',\n",
    "           activation = 'relu')(Inputs)\n",
    "x = Conv2D(filters=4, kernel_size=(3,3), strides=(2,2), padding='same',\n",
    "           kernel_initializer='he_normal', use_bias=True, name='conv2_relu',\n",
    "           activation = 'relu')(x)\n",
    "x = Conv2D(filters=2, kernel_size=(3,3), strides=(2,2), padding='same',\n",
    "           kernel_initializer='he_normal', use_bias=True, name='conv3_relu',\n",
    "           activation = 'relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "predictions = Dense(5, activation='softmax', kernel_initializer='lecun_uniform', name='output_softmax')(x)\n",
    "model = Model(inputs=Inputs, outputs=predictions)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 1024, epochs = 100,\n",
    "                    validation_split = 0.25, shuffle = True, callbacks = None, \n",
    "                    use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurveLoss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], linewidth=1)\n",
    "    plt.plot(history.history['val_loss'], linewidth=1)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningCurveLoss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRoc(features_val, labels_val, labels, model, outputSuffix=''):\n",
    "    labels_pred = model.predict(features_val)\n",
    "    df = pd.DataFrame()\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    auc1 = {}\n",
    "    plt.figure()       \n",
    "    for i, label in enumerate(labels):\n",
    "        df[label] = labels_val[:,i]\n",
    "        df[label + '_pred'] = labels_pred[:,i]\n",
    "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
    "        auc1[label] = auc(fpr[label], tpr[label])\n",
    "        plt.plot(fpr[label],tpr[label],label='%s tagger, AUC = %.1f%%'%(label.replace('j_',''),auc1[label]*100.))\n",
    "    plt.xlabel(\"Background Efficiency\")\n",
    "    plt.ylabel(\"Signal Efficiency\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim(0.001,1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('%s ROC Curve'%(outputSuffix))\n",
    "    plt.savefig('%s_ROC_Curve.png'%(outputSuffix))\n",
    "    return labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = makeRoc(X_test, y_test, labels, model, outputSuffix='Conv2d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "Try other resolutions like 80x80 and see if the result performance would be better or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
